{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework and bake-off: Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kisukjang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch import Tensor\n",
    "import io\n",
    "import time\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_train_url = 'train.en.gz'\n",
    "eng_val_url = 'val.en.gz'\n",
    "eng_test_url = 'test_2016_flickr.en.gz'\n",
    "eng_spacy_lng = 'en_core_web_sm'\n",
    "\n",
    "dst_train_url = 'train.fr.gz'\n",
    "dst_val_url = 'val.fr.gz'\n",
    "dst_test_url = 'test_2016_flickr.fr.gz'\n",
    "dst_spacy_lng = 'fr_core_news_sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AG_NEWS Train size: 120000\n",
      "AG_NEWS Test size: 7600\n",
      "YELP FULL Train size: 144750\n",
      "YELP FULL Test size: 7600\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import AG_NEWS, YelpReviewFull\n",
    "\n",
    "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
    "train_urls = (eng_train_url, dst_train_url)\n",
    "val_urls = (eng_val_url, dst_val_url)\n",
    "test_urls = (eng_test_url, dst_test_url)\n",
    "\n",
    "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
    "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
    "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n",
    "\n",
    "eng_lng_tokenizer = get_tokenizer('spacy', language=eng_spacy_lng)\n",
    "dst_lng_tokenizer = get_tokenizer('spacy', language=dst_spacy_lng)\n",
    "# classification_tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Torchtext dataset\n",
    "ag_train_iter, ag_test_iter = AG_NEWS()\n",
    "ag_train_list = list(ag_train_iter)\n",
    "ag_test_list = list(ag_test_iter)\n",
    "ag_train_list_sub = ag_train_list[:int(len(ag_train_list) / 24)]\n",
    "ag_test_list_sub = ag_test_list[:int(len(ag_test_list) / 15)]\n",
    "yelp_train_iter, yelp_test_iter = YelpReviewFull()\n",
    "yelp_train_list = list(yelp_train_iter)\n",
    "yelp_test_list = list(yelp_test_iter)\n",
    "yelp_train_list_sub = yelp_train_list[:int(len(yelp_train_list) / 130)]\n",
    "yelp_test_list_sub = yelp_test_list[:int(len(yelp_test_list) / 15)]\n",
    "\n",
    "print(\"AG_NEWS Train size:\", len(ag_train_list))\n",
    "print(\"AG_NEWS Test size:\", len(ag_test_list))\n",
    "print(\"YELP FULL Train size:\", len(yelp_train_list))\n",
    "print(\"YELP FULL Test size:\", len(ag_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destination language vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dest Vocab size: 11510\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "with io.open(train_filepaths[1], encoding=\"utf8\") as f:\n",
    "    for string_ in f:\n",
    "        counter.update(dst_lng_tokenizer(string_))\n",
    "dst_lng_vocab = Vocab(counter, min_freq=1, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "DST_VOCAB_SIZE = len(dst_lng_vocab)\n",
    "print(\"Dest Vocab size:\", DST_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English language vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab size: 225404\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "with io.open(train_filepaths[0], encoding=\"utf8\") as f:\n",
    "    for string_ in f:\n",
    "        counter.update(eng_lng_tokenizer(string_))\n",
    "for i in range(len(ag_train_list)):\n",
    "    if \"\\\\\" in ag_train_list[i][1]:\n",
    "        ag_train_list[i] = (ag_train_list[i][0], ag_train_list[i][1].replace(\"\\\\\", \" \"))\n",
    "    counter.update(eng_lng_tokenizer(ag_train_list[i][1]))\n",
    "for i in range(len(yelp_train_list)):\n",
    "    if \"\\\\n\\\\n\" in yelp_train_list[i][1]:\n",
    "        yelp_train_list[i] = (yelp_train_list[i][0], yelp_train_list[i][1].replace(\"\\\\n\\\\n\", \" \"))\n",
    "        yelp_train_list[i] = (yelp_train_list[i][0], yelp_train_list[i][1].replace(\"\\\\n\", \" \"))\n",
    "        yelp_train_list[i] = (yelp_train_list[i][0], yelp_train_list[i][1].replace(\"\\\\\", \"\"))\n",
    "    counter.update(eng_lng_tokenizer(yelp_train_list[i][1]))\n",
    "\n",
    "eng_lng_vocab = Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "ENG_VOCAB_SIZE = len(eng_lng_vocab)\n",
    "print(\"English Vocab size:\", ENG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = eng_lng_vocab['<pad>']\n",
    "BOS_IDX = eng_lng_vocab['<bos>']\n",
    "EOS_IDX = eng_lng_vocab['<eos>']\n",
    "print(PAD_IDX)\n",
    "print(BOS_IDX)\n",
    "print(EOS_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init tokens\n",
    "def data_process(filepaths):\n",
    "    raw_eng_lng_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
    "    raw_dst_lng_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
    "    data = []\n",
    "    for (raw_eng, raw_dst) in zip(raw_eng_lng_iter, raw_dst_lng_iter):\n",
    "        eng_lng_tensor_ = torch.tensor([eng_lng_vocab[token] for token in eng_lng_tokenizer(raw_eng.rstrip(\"\\n\"))],\n",
    "                                dtype=torch.long)\n",
    "        dst_lng_tensor_ = torch.tensor([dst_lng_vocab[token] for token in dst_lng_tokenizer(raw_dst.rstrip(\"\\n\"))],\n",
    "                                dtype=torch.long)\n",
    "        data.append((eng_lng_tensor_, dst_lng_tensor_))\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = data_process(train_filepaths)\n",
    "val_data = data_process(val_filepaths)\n",
    "test_data = data_process(test_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 29000\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    dst_lng_batch, src_lng_batch = [], []\n",
    "    for (src_lng_item, dst_lng_item) in data_batch:\n",
    "        dst_lng_batch.append(torch.cat([torch.tensor([BOS_IDX]), dst_lng_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        src_lng_batch.append(torch.cat([torch.tensor([BOS_IDX]), src_lng_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    dst_lng_batch = pad_sequence(dst_lng_batch, padding_value=PAD_IDX)\n",
    "    src_lng_batch = pad_sequence(src_lng_batch, padding_value=PAD_IDX)\n",
    "    return src_lng_batch, dst_lng_batch\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn=generate_batch)\n",
    "\n",
    "print(\"Train count:\", len(train_iter.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if data looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  95, 2085, 1173,  ...,   95,   95,   95],\n",
      "        [ 370, 1473, 2253,  ...,  257,  641,  235],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  8,  17,  71,  ...,   8,  17,   8],\n",
      "        [187, 177,  39,  ...,  14,  32,  73],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "for idx, (src, tgt) in enumerate(train_iter):\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model\n",
    "\n",
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
    "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a subsequent word mask to stop a target word from attending to its subsequent words. We also create masks, for masking source and target padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "Define model parameters and instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, ENG_VOCAB_SIZE, DST_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iter, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in enumerate(train_iter):\n",
    "        src = src.to(device) # Output: maxLen(seq_src) x Batch_Size\n",
    "        tgt = tgt.to(device) # Output: maxLen(seq_tgt) x Batch_Size\n",
    "\n",
    "        print(src.shape)\n",
    "        print(tgt.shape)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                                src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        # Output: (maxLen(seq_tgt)-1) x Batch_Size x DST_LNG_VOCAB\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        # ((maxLen(seq_tgt)-1) x Batch_Size) x DST_LNG_VOCAB, ((maxLen(seq_tgt)-1) x Batch_Size)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses += loss.item()\n",
    "    return losses / len(train_iter)\n",
    "\n",
    "\n",
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in (enumerate(valid_iter)):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                                  src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "    return losses / len(val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train_epoch(transformer, train_iter, optimizer)\n",
    "#     end_time = time.time()\n",
    "# #     val_loss = evaluate(transformer, valid_iter)\n",
    "#     val_loss = 0\n",
    "#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
    "#           f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models trained using transformer architecture — train faster and converge to a lower validation loss compared to RNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation Model In-Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask) # Output: len(YS) x 1 x 512\n",
    "        out = out.transpose(0, 1) # Output: 1 x len(YS) x 512\n",
    "        prob = model.generator(out[:, -1]) # Output: 1 x 512 -> 1 x DST_LNG_VOCAB\n",
    "        _, next_word = torch.max(prob, dim = 1) # Output: 1\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "         # Output: 1 x len(YS) -> 1 x (len(YS) + 1)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
    "    model.eval()\n",
    "    tokens = [BOS_IDX] + [src_vocab.stoi[tok] for tok in src_tokenizer(src)]+ [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join([tgt_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1, 512])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 1, 512])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1, 512])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4, 1, 512])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Des citoyens jouent . '"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(transformer_model, \"Hello\", eng_lng_vocab, dst_lng_vocab, eng_lng_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load Model\n",
    "\n",
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './translation_model_eng_to_fr2.pt'\n",
    "\n",
    "# torch.save(transformer, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './translation_model_eng_to_fr2.pt'\n",
    "\n",
    "transformer_model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Tous les airs pour les bases '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(transformer_model, \"My name is John\", eng_lng_vocab, dst_lng_vocab, eng_lng_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Style Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-label\n",
    "new_ag_train_list = []\n",
    "new_ag_test_list = []\n",
    "new_yelp_train_list = []\n",
    "new_yelp_test_list = []\n",
    "for i in range(len(ag_train_list)):\n",
    "    new_ag_train_list.append((1, ag_train_list[i][1]))\n",
    "for i in range(len(ag_test_list)):\n",
    "    new_ag_test_list.append((1, ag_test_list[i][1]))\n",
    "for i in range(len(yelp_train_list)):\n",
    "    new_yelp_train_list.append((2, yelp_train_list[i][1]))\n",
    "for i in range(len(yelp_test_list)):\n",
    "    new_yelp_test_list.append((2, yelp_test_list[i][1]))\n",
    "    \n",
    "train_dataset = new_ag_train_list + new_yelp_train_list\n",
    "test_dataset = new_ag_test_list + new_yelp_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 251512\n",
      "Val size: 13238\n",
      "Test size: 57600\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        text_list.append(torch.cat([torch.tensor([BOS_IDX]), \n",
    "                                    torch.tensor(text_pipeline(_text), dtype=torch.int64), \n",
    "                                    torch.tensor([EOS_IDX])], dim=0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.transpose(pad_sequence(text_list, padding_value=PAD_IDX), 0, 1)\n",
    "    return label_list.to(device), text_list.to(device)\n",
    "\n",
    "num_class = 2\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "print(\"Train size:\", len(train_dataloader.dataset))\n",
    "print(\"Val size:\", len(valid_dataloader.dataset))\n",
    "print(\"Test size:\", len(test_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [eng_lng_vocab[token] for token in eng_lng_tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 16, 5, 54, 2625]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('here is the an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emsize = 64\n",
    "classification_model = TextClassificationModel(ENG_VOCAB_SIZE, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    classification_model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = classification_model(text) # BATCH_SIZE x maxLen(text)\n",
    "        # Output: BATCH_SIZE x C\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(classification_model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    classification_model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predited_label = classification_model(text)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = train_dataset[:2]\n",
    "temp_dataloader = DataLoader(temp_data, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "# EPOCHS = 5 # epoch\n",
    "# LR = 1  # learning rate\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(classification_model.parameters(), lr=LR)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "# total_accu = None\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     epoch_start_time = time.time()\n",
    "#     train(train_dataloader)\n",
    "#     accu_val = evaluate(valid_dataloader)\n",
    "#     if total_accu is not None and total_accu > accu_val:\n",
    "#         scheduler.step()\n",
    "#     else:\n",
    "#         total_accu = accu_val\n",
    "#     print('-' * 59)\n",
    "#     print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "#           'valid accuracy {:8.3f} '.format(epoch,\n",
    "#                                            time.time() - epoch_start_time,\n",
    "#                                            accu_val))\n",
    "#     print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Checking the results of test dataset.')\n",
    "# accu_test = evaluate(test_dataloader)\n",
    "# print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a YELP style\n"
     ]
    }
   ],
   "source": [
    "style_label = {1: \"AG_NEWS\",\n",
    "               2: \"YELP\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.cat([torch.tensor([BOS_IDX]), \n",
    "                                    torch.tensor(text_pipeline(text), dtype=torch.int64), \n",
    "                                    torch.tensor([EOS_IDX])], dim=0)\n",
    "        text = torch.reshape(text, (1, text.shape[0]))\n",
    "        output = classification_model(text)\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "ex_text_str = \"I think food is not so bad.\"\n",
    "\n",
    "classification_model = classification_model.to(\"cpu\")\n",
    "classification_model.eval()\n",
    "\n",
    "print(\"This is a %s style\" %style_label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# PATH_CLS = './classification_model.pt'\n",
    "\n",
    "# torch.save(classification_model, PATH_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CLS = './classification_model.pt'\n",
    "\n",
    "classification_model = torch.load(PATH_CLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Style Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize & Re-label\n",
    "train_data = []\n",
    "test_data = []\n",
    "for i in range(len(ag_train_list_sub)):\n",
    "    sentences = sent_tokenize(ag_train_list_sub[i][1])\n",
    "    for sentence in sentences:\n",
    "        text_tensor = torch.tensor([eng_lng_vocab[token] for token in eng_lng_tokenizer(sentence.rstrip(\"\\n\"))], dtype=torch.long)\n",
    "        train_data.append((2, text_tensor))\n",
    "for i in range(len(ag_test_list_sub)):\n",
    "    sentences = sent_tokenize(ag_test_list_sub[i][1])\n",
    "    for sentence in sentences:\n",
    "        text_tensor = torch.tensor([eng_lng_vocab[token] for token in eng_lng_tokenizer(sentence.rstrip(\"\\n\"))], dtype=torch.long)\n",
    "        test_data.append((2, text_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6389\n",
      "Val size: 337\n",
      "Test size: 709\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# Split dataset\n",
    "num_class = 2\n",
    "num_train = int(len(train_data) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_data, [num_train, len(train_data) - num_train])\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text_tensor) in batch:\n",
    "        label_list.append(_label - 1)\n",
    "        new_tensor = torch.cat([torch.tensor([BOS_IDX]), _text_tensor, torch.tensor([EOS_IDX])], dim=0)\n",
    "        text_list.append(new_tensor)\n",
    "        \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list, padding_value=PAD_IDX)\n",
    "    return label_list.to(device), text_list.to(device)\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "print(\"Train size:\", len(train_dataloader.dataset))\n",
    "print(\"Val size:\", len(valid_dataloader.dataset))\n",
    "print(\"Test size:\", len(test_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStyleGenerator(nn.Module):\n",
    "    def __init__(self, num_decoder_layers: int,\n",
    "                 emb_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(TextStyleGenerator, self).__init__()\n",
    "        \n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "        \n",
    "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, memory: Tensor, trg: Tensor, tgt_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, dataloader, crit1, crit2):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        print(text.shape)\n",
    "        src = text\n",
    "        tgt_input = text[:-1, :] # Output: maxLen(text) x BATCH_SIZE\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        \n",
    "        # Encode first\n",
    "        memory = transformer_model.encode(src, src_mask)\n",
    "        # Output: maxLen(text) x BATCH_SIZE x 512\n",
    "        \n",
    "        # Train decoder\n",
    "        logits = model(memory, tgt_input, tgt_mask, tgt_padding_mask, src_padding_mask) \n",
    "        # Output: maxLen(text) x BATCH_SIZE x ENG_LNG_VOCAB\n",
    "        \n",
    "        # Calculate loss\n",
    "        tgt_out = text[1:,:]\n",
    "#         loss_reconst = crit1(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        # ((maxLen(text)-1) x Batch_Size) x DST_LNG_VOCAB, ((maxLen(text)-1) x Batch_Size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ys = torch.ones(1, text.shape[1]).fill_(BOS_IDX).type(torch.long).to(device)\n",
    "        for i in range(text.shape[0] + 5 - 1):\n",
    "            tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                        .type(torch.bool)).to(device)\n",
    "            \n",
    "            out = model.decode(ys, memory, tgt_mask) # Output: maxLen(text) x BATCH_SIZE x 512\n",
    "            out = out.transpose(0, 1) # Output: BATCH_SIZE x maxLen(text) x 512\n",
    "            prob = model.generator(out[:, -1]) # Output: BATCH_SIZE x 512 -> BATCH_SIZE x DST_LNG_VOCAB\n",
    "            _, next_word = torch.max(prob, dim = 1) # Output: BATCH_SIZE\n",
    "            next_word = torch.reshape(next_word, (1, next_word.shape[0])) # Output: 1 x BATCH_SIZE\n",
    "            ys = torch.cat([ys, next_word.type_as(src.data)], dim=0)\n",
    "            \n",
    "            end_count = (next_word == EOS_IDX).sum(dim=1) + (next_word == PAD_IDX).sum(dim=1)\n",
    "            if end_count == next_word.shape[1]:\n",
    "                break\n",
    "        # Output: LEN x BATCH_SIZE\n",
    "        \n",
    "        style_text = torch.transpose(ys, 0, 1)\n",
    "        print(style_text)\n",
    "        \n",
    "        for i in range(style_text.shape[0]):\n",
    "            print(\" \".join([eng_lng_vocab.itos[tok] for tok in style_text[i]]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
    "            for j in range(style_text.shape[1]):\n",
    "                print(eng_lng_vocab.itos[style_text[i][j]])\n",
    "        predited_label = classification_model(style_text) # BATCH_SIZE x maxLen(text)\n",
    "        loss_class = crit2(predited_label, label)\n",
    "        \n",
    "        loss = loss_class\n",
    "#         loss = loss_reconst + loss_class\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "#         if idx % 10 == 0:\n",
    "#         val_loss = evaluate(text_styler, valid_dataloader, crit1)\n",
    "        val_loss = 0\n",
    "        print((f\"Epoch: {epoch}, Train loss: {running_loss:.3f}, Val loss: {val_loss:.3f}\"))\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "def evaluate(model, dataloader, crit1):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            src = text\n",
    "            tgt_input = text[:-1, :]\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        \n",
    "            # Encode first\n",
    "            memory = transformer.encode(src, src_mask)\n",
    "\n",
    "            # Train decoder\n",
    "            logits = model(memory, tgt_input, tgt_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "            # Calculate loss\n",
    "            tgt_out = text[1:,:]\n",
    "            loss = crit1(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            losses += loss.item()\n",
    "\n",
    "        return losses / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = train_data[:2]\n",
    "temp_dataloader = DataLoader(temp_data, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 2])\n",
      "tensor([[     2,  83483, 273738, 126700, 209833,  83483,  50272, 267116, 231416,\n",
      "          83483, 345255,  92555,  50272,  92555,  50272, 234095,  53835,  83483,\n",
      "          83483,  50478, 215033, 312645,  66285, 153089, 104018, 254160,  11801,\n",
      "         312645,  11801, 274981,  50272, 166346,  50272,  83483,  15318, 330799,\n",
      "         196605,   6680,  83483,  11801, 195623, 220180,  50272, 188971,  83483,\n",
      "         329397,  66285, 349444, 328808],\n",
      "        [     2,  43256, 224681,  11801,  94579, 215033, 231416, 323060, 130589,\n",
      "          84258,  18201, 104018,  92555, 125301, 163263,  50272,  50272,  83483,\n",
      "         307677,  83483, 339933,  80877,  50272,  43743,  11801,  83483,   4515,\n",
      "          11801,  11801,  57063, 142577, 319788,  50272, 344249, 182459,  83483,\n",
      "         188971,  96352, 188971,  22503,  50272, 178691,  50272, 125540,  50272,\n",
      "          50272, 338693, 234466, 104018]])\n",
      " Queues ineffectual stale.\\n\\nOur \\nCz Queues \\\"right\\ happy.\\n\\nYour busisness Queues went.\\n\\nSo sandwiches.\\n\\nThey \\\"right\\ sandwiches.\\n\\nThey \\\"right\\ chambered \\\"everything\\ Queues Queues averse \\r\\nMy rib.\\n\\nI knotch Cincinnati.]\\n\\nI'm NYEastman experience.\\n\\n****This Spent rib.\\n\\nI Spent irrelevant.\\\"\\n\\nSince \\\"right\\ IMAG0832.jpg \\\"right\\ Queues militiamen tender.\\n\\n WOWZA eve Queues Spent Vegas.\\n\\nPro anything!\\n\\nMy \\\"right\\ Snobs Queues tables.\\n\\nThat knotch yummiest.\\n\\nTheir sweeeet\n",
      "<bos>\n",
      "Queues\n",
      "ineffectual\n",
      "stale.\\n\\nOur\n",
      "\\nCz\n",
      "Queues\n",
      "\\\"right\\\n",
      "happy.\\n\\nYour\n",
      "busisness\n",
      "Queues\n",
      "went.\\n\\nSo\n",
      "sandwiches.\\n\\nThey\n",
      "\\\"right\\\n",
      "sandwiches.\\n\\nThey\n",
      "\\\"right\\\n",
      "chambered\n",
      "\\\"everything\\\n",
      "Queues\n",
      "Queues\n",
      "averse\n",
      "\\r\\nMy\n",
      "rib.\\n\\nI\n",
      "knotch\n",
      "Cincinnati.]\\n\\nI'm\n",
      "NYEastman\n",
      "experience.\\n\\n****This\n",
      "Spent\n",
      "rib.\\n\\nI\n",
      "Spent\n",
      "irrelevant.\\\"\\n\\nSince\n",
      "\\\"right\\\n",
      "IMAG0832.jpg\n",
      "\\\"right\\\n",
      "Queues\n",
      "militiamen\n",
      "tender.\\n\\n\n",
      "WOWZA\n",
      "eve\n",
      "Queues\n",
      "Spent\n",
      "Vegas.\\n\\nPro\n",
      "anything!\\n\\nMy\n",
      "\\\"right\\\n",
      "Snobs\n",
      "Queues\n",
      "tables.\\n\\nThat\n",
      "knotch\n",
      "yummiest.\\n\\nTheir\n",
      "sweeeet\n",
      " service\\n- baked\\ Spent .\\n\\nAfter \\r\\nMy busisness sorcery -90 Societe OK\\ NYEastman sandwiches.\\n\\nThey ripper Granieri \\\"right\\ \\\"right\\ Queues quot;consultancy Queues unreflective Fagoli \\\"right\\ Cast Spent Queues vendor Spent Spent KOREA ?\\n\\n shot(tasted \\\"right\\ way\\\" R.A.#\\nWhen Queues Snobs 9.48 Snobs tattered \\\"right\\ P!\\n\\nThe \\\"right\\ same.\\nI \\\"right\\ \\\"right\\ two\\blasts charges\\nUnprofessional NYEastman\n",
      "<bos>\n",
      "service\\n-\n",
      "baked\\\n",
      "Spent\n",
      ".\\n\\nAfter\n",
      "\\r\\nMy\n",
      "busisness\n",
      "sorcery\n",
      "-90\n",
      "Societe\n",
      "OK\\\n",
      "NYEastman\n",
      "sandwiches.\\n\\nThey\n",
      "ripper\n",
      "Granieri\n",
      "\\\"right\\\n",
      "\\\"right\\\n",
      "Queues\n",
      "quot;consultancy\n",
      "Queues\n",
      "unreflective\n",
      "Fagoli\n",
      "\\\"right\\\n",
      "Cast\n",
      "Spent\n",
      "Queues\n",
      "vendor\n",
      "Spent\n",
      "Spent\n",
      "KOREA\n",
      "?\\n\\n\n",
      "shot(tasted\n",
      "\\\"right\\\n",
      "way\\\"\n",
      "R.A.#\\nWhen\n",
      "Queues\n",
      "Snobs\n",
      "9.48\n",
      "Snobs\n",
      "tattered\n",
      "\\\"right\\\n",
      "P!\\n\\nThe\n",
      "\\\"right\\\n",
      "same.\\nI\n",
      "\\\"right\\\n",
      "\\\"right\\\n",
      "two\\blasts\n",
      "charges\\nUnprofessional\n",
      "NYEastman\n",
      "Epoch: 1, Train loss: 8.298, Val loss: 0.000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PATH_FINAL_TMP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-0dc612b54bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_styler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_styler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH_FINAL_TMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'PATH_FINAL_TMP' is not defined"
     ]
    }
   ],
   "source": [
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "\n",
    "text_styler = TextStyleGenerator(NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, ENG_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "\n",
    "for p in text_styler.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "text_styler = text_styler.to(device)\n",
    "\n",
    "crit1 = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "crit2 = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    text_styler.parameters(), lr=0.0005, betas=(0.9, 0.99), eps=1e-8\n",
    ")\n",
    "\n",
    "transformer_model.eval()\n",
    "classification_model.eval()\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    train_loss = train(text_styler, temp_dataloader, crit1, crit2)\n",
    "    torch.save(text_styler, PATH_FINAL_TMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "    \n",
    "    transformer.eval()\n",
    "    \n",
    "    memory = transformer.encode(src, src_mask)\n",
    "\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(device)\n",
    "        \n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def transfer(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
    "    model.eval()\n",
    "    tokens = [BOS_IDX] + [src_vocab.stoi[tok] for tok in src_tokenizer(src)]+ [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join([tgt_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_train_list_sub[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer(text_styler, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", eng_lng_vocab, eng_lng_vocab, eng_lng_tokenizer)\n",
    "transfer(text_styler, \"No way here you go\", eng_lng_vocab, eng_lng_vocab, eng_lng_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_FINAL = './final_model.pt'\n",
    "\n",
    "# torch.save(text_styler, PATH_FINAL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
