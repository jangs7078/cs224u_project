{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework and bake-off: Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sunmilee/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch import Tensor\n",
    "import io\n",
    "import time\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_train_url = 'train.en.gz'\n",
    "eng_val_url = 'val.en.gz'\n",
    "eng_test_url = 'test_2016_flickr.en.gz'\n",
    "eng_spacy_lng = 'en_core_web_sm'\n",
    "\n",
    "dst_train_url = 'train.fr.gz'\n",
    "dst_val_url = 'val.fr.gz'\n",
    "dst_test_url = 'test_2016_flickr.fr.gz'\n",
    "dst_spacy_lng = 'fr_core_news_sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.csv: 29.5MB [00:01, 14.8MB/s]                            \n",
      "test.csv: 1.86MB [00:00, 12.5MB/s]                  \n",
      "yelp_review_full_csv.tar.gz: 196MB [00:05, 37.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AG_NEWS Train size: 120000\n",
      "AG_NEWS Test size: 7600\n",
      "YELP FULL Train size: 650000\n",
      "YELP FULL Test size: 7600\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import AG_NEWS, YelpReviewFull\n",
    "\n",
    "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
    "train_urls = (eng_train_url, dst_train_url)\n",
    "val_urls = (eng_val_url, dst_val_url)\n",
    "test_urls = (eng_test_url, dst_test_url)\n",
    "\n",
    "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
    "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
    "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n",
    "\n",
    "eng_lng_tokenizer = get_tokenizer('spacy', language=eng_spacy_lng)\n",
    "dst_lng_tokenizer = get_tokenizer('spacy', language=dst_spacy_lng)\n",
    "classification_tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Torchtext dataset\n",
    "ag_train_iter, ag_test_iter = AG_NEWS()\n",
    "ag_train_list = list(ag_train_iter)\n",
    "ag_test_list = list(ag_test_iter)\n",
    "ag_train_list_sub = ag_train_list[:int(len(ag_train_list) / 24)]\n",
    "ag_test_list_sub = ag_test_list[:int(len(ag_test_list) / 15)]\n",
    "yelp_train_iter, yelp_test_iter = YelpReviewFull()\n",
    "yelp_train_list = list(yelp_train_iter)\n",
    "yelp_test_list = list(yelp_test_iter)\n",
    "yelp_train_list_sub = yelp_train_list[:int(len(yelp_train_list) / 130)]\n",
    "yelp_test_list_sub = yelp_test_list[:int(len(yelp_test_list) / 15)]\n",
    "\n",
    "print(\"AG_NEWS Train size:\", len(ag_train_list))\n",
    "print(\"AG_NEWS Test size:\", len(ag_test_list))\n",
    "print(\"YELP FULL Train size:\", len(yelp_train_list))\n",
    "print(\"YELP FULL Test size:\", len(ag_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destination language vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dest Vocab size: 11510\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "with io.open(train_filepaths[1], encoding=\"utf8\") as f:\n",
    "    for string_ in f:\n",
    "        counter.update(dst_lng_tokenizer(string_))\n",
    "dst_lng_vocab = Vocab(counter, min_freq=1, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "DST_VOCAB_SIZE = len(dst_lng_vocab)\n",
    "print(\"Dest Vocab size:\", DST_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English language vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab size: 48940\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "with io.open(train_filepaths[0], encoding=\"utf8\") as f:\n",
    "    for string_ in f:\n",
    "        counter.update(eng_lng_tokenizer(string_))\n",
    "for i in range(len(ag_train_list_sub)):\n",
    "    counter.update(eng_lng_tokenizer(ag_train_list_sub[i][1]))\n",
    "for i in range(len(yelp_train_list_sub)):\n",
    "    counter.update(eng_lng_tokenizer(yelp_train_list_sub[i][1]))\n",
    "eng_lng_vocab = Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "ENG_VOCAB_SIZE = len(eng_lng_vocab)\n",
    "print(\"English Vocab size:\", ENG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Vocab size: 570177\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "for i in range(len(ag_train_list)):\n",
    "    counter.update(classification_tokenizer(ag_train_list[i][1]))\n",
    "for i in range(len(yelp_train_list)):\n",
    "    counter.update(classification_tokenizer(yelp_train_list[i][1]))\n",
    "classification_vocab = Vocab(counter, min_freq=1)\n",
    "\n",
    "CLF_VOCAB_SIZE = len(classification_vocab)\n",
    "print(\"Classification Vocab size:\", CLF_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = eng_lng_vocab['<pad>']\n",
    "BOS_IDX = eng_lng_vocab['<bos>']\n",
    "EOS_IDX = eng_lng_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init tokens\n",
    "def data_process(filepaths):\n",
    "    raw_eng_lng_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
    "    raw_dst_lng_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
    "    data = []\n",
    "    for (raw_eng, raw_dst) in zip(raw_eng_lng_iter, raw_dst_lng_iter):\n",
    "        eng_lng_tensor_ = torch.tensor([eng_lng_vocab[token] for token in eng_lng_tokenizer(raw_eng.rstrip(\"\\n\"))],\n",
    "                                dtype=torch.long)\n",
    "        dst_lng_tensor_ = torch.tensor([dst_lng_vocab[token] for token in dst_lng_tokenizer(raw_dst.rstrip(\"\\n\"))],\n",
    "                                dtype=torch.long)\n",
    "        data.append((eng_lng_tensor_, dst_lng_tensor_))\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = data_process(train_filepaths)\n",
    "val_data = data_process(val_filepaths)\n",
    "test_data = data_process(test_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 29000\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    dst_lng_batch, src_lng_batch = [], []\n",
    "    for (src_lng_item, dst_lng_item) in data_batch:\n",
    "        dst_lng_batch.append(torch.cat([torch.tensor([BOS_IDX]), dst_lng_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        src_lng_batch.append(torch.cat([torch.tensor([BOS_IDX]), src_lng_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    dst_lng_batch = pad_sequence(dst_lng_batch, padding_value=PAD_IDX)\n",
    "    src_lng_batch = pad_sequence(src_lng_batch, padding_value=PAD_IDX)\n",
    "    return src_lng_batch, dst_lng_batch\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn=generate_batch)\n",
    "\n",
    "print(\"Train count:\", len(train_iter.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if data looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  14, 2501,  179,  ...,   14,   14,   14],\n",
      "        [ 303,  501,  440,  ...,   25,   79,  144],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  8,  17,  71,  ...,   8,  17,   8],\n",
      "        [187, 177,  39,  ...,  14,  32,  73],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "for idx, (src, tgt) in enumerate(train_iter):\n",
    "    src = src.to(device)\n",
    "    tgt = tgt.to(device)\n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model\n",
    "\n",
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
    "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Position Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a subsequent word mask to stop a target word from attending to its subsequent words. We also create masks, for masking source and target padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "Define model parameters and instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "NUM_EPOCHS = 16\n",
    "\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, ENG_VOCAB_SIZE, DST_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iter, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in enumerate(train_iter):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                                src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses += loss.item()\n",
    "    return losses / len(train_iter)\n",
    "\n",
    "\n",
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in (enumerate(valid_iter)):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                                  src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "    return losses / len(val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(transformer, train_iter, optimizer)\n",
    "    end_time = time.time()\n",
    "    val_loss = evaluate(transformer, valid_iter)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models trained using transformer architecture — train faster and converge to a lower validation loss compared to RNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation Model In-Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
    "    model.eval()\n",
    "    tokens = [BOS_IDX] + [src_vocab.stoi[tok] for tok in src_tokenizer(src)]+ [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join([tgt_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(transformer, \"Hello\", eng_lng_vocab, dst_lng_vocab, eng_lng_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load Model\n",
    "\n",
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './translation_model_eng_to_fr_full.pt'\n",
    "\n",
    "torch.save(transformer, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(transformer_model, \"My name is John\", eng_lng_vocab, dst_lng_vocab, eng_lng_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Style Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchtext.datasets import AG_NEWS, YelpReviewFull\n",
    "# train_iter = YelpReviewFull(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "# Re-label\n",
    "new_ag_train_list = []\n",
    "new_ag_test_list = []\n",
    "new_yelp_train_list = []\n",
    "new_yelp_test_list = []\n",
    "for i in range(len(ag_train_list)):\n",
    "    new_ag_train_list.append((1, ag_train_list[i][1]))\n",
    "for i in range(len(ag_test_list)):\n",
    "    new_ag_test_list.append((1, ag_test_list[i][1]))\n",
    "for i in range(len(yelp_train_list)):\n",
    "    new_yelp_train_list.append((2, yelp_train_list[i][1]))\n",
    "for i in range(len(yelp_test_list)):\n",
    "    new_yelp_test_list.append((2, yelp_test_list[i][1]))\n",
    "    \n",
    "train_dataset = new_ag_train_list + new_yelp_train_list\n",
    "test_dataset = new_ag_test_list + new_yelp_test_list\n",
    "\n",
    "num_class = 2\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "print(\"Train size:\", len(train_dataloader.dataset))\n",
    "print(\"Val size:\", len(valid_dataloader.dataset))\n",
    "print(\"Test size:\", len(test_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [classification_vocab[token] for token in classification_tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline('here is the an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pipeline(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emsize = 64\n",
    "classification_model = TextClassificationModel(CLF_VOCAB_SIZE, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    classification_model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = classification_model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(classification_model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    classification_model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = classification_model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(classification_model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_label = {1: \"AG_NEWS\",\n",
    "               2: \"YELP\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = classification_model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "# ex_text_str = \"I think food is not so bad.\"\n",
    "\n",
    "classification_model = classification_model.to(\"cpu\")\n",
    "\n",
    "print(\"This is a %s style\" %style_label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "PATH_CLS = './classification_model.pt'\n",
    "\n",
    "torch.save(classification_model, PATH_CLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Style Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# Tokenize & Re-label\n",
    "train_data = []\n",
    "test_data = []\n",
    "for i in range(len(ag_train_list_sub)):\n",
    "    sentences = sent_tokenize(ag_train_list_sub[i][1])\n",
    "    for sentence in sentences:\n",
    "        text_tensor = torch.tensor([eng_lng_vocab[token] for token in eng_lng_tokenizer(sentence.rstrip(\"\\n\"))], dtype=torch.long)\n",
    "        train_data.append((2, text_tensor))\n",
    "for i in range(len(ag_test_list_sub)):\n",
    "    sentences = sent_tokenize(ag_test_list_sub[i][1])\n",
    "    for sentence in sentences:\n",
    "        text_tensor = torch.tensor([eng_lng_vocab[token] for token in eng_lng_tokenizer(sentence.rstrip(\"\\n\"))], dtype=torch.long)\n",
    "        test_data.append((2, text_tensor))\n",
    "\n",
    "# Split dataset\n",
    "num_class = 2\n",
    "num_train = int(len(train_data) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_data, [num_train, len(train_data) - num_train])\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text_tensor) in batch:\n",
    "        label_list.append(_label - 1)\n",
    "        new_tensor = torch.cat([torch.tensor([BOS_IDX]), _text_tensor, torch.tensor([EOS_IDX])], dim=0)\n",
    "        text_list.append(new_tensor)\n",
    "        \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list, padding_value=PAD_IDX)\n",
    "    return label_list.to(device), text_list.to(device)\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "print(\"Train size:\", len(train_dataloader.dataset))\n",
    "print(\"Val size:\", len(valid_dataloader.dataset))\n",
    "print(\"Test size:\", len(test_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStyleGenerator(nn.Module):\n",
    "    def __init__(self, num_decoder_layers: int,\n",
    "                 emb_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(TextStyleGenerator, self).__init__()\n",
    "        \n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "        \n",
    "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, memory: Tensor, trg: Tensor, tgt_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_DECODER_LAYERS = 3\n",
    "NUM_EPOCHS = 16\n",
    "\n",
    "\n",
    "text_styler = TextStyleGenerator(NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, ENG_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "\n",
    "for p in text_styler.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "text_styler = text_styler.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    text_styler.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, dataloader, crit1):\n",
    "    transformer.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        src = text\n",
    "        tgt_input = text[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        \n",
    "        # Encode first\n",
    "        memory = transformer.encode(src, src_mask)\n",
    "        \n",
    "        # Train decoder\n",
    "        logits = model(memory, tgt_input, tgt_mask, tgt_padding_mask, src_padding_mask)\n",
    "        \n",
    "        # Calculate loss\n",
    "        tgt_out = text[1:,:]\n",
    "        loss = crit1(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "#         if idx % 10 == 0:\n",
    "        val_loss = evaluate(text_styler, valid_dataloader, crit1)\n",
    "        print((f\"Epoch: {epoch}, Train loss: {running_loss:.3f}, Val loss: {val_loss:.3f}\"))\n",
    "        running_loss = 0.0\n",
    "\n",
    "def evaluate(model, dataloader, crit1):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            src = text\n",
    "            tgt_input = text[:-1, :]\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        \n",
    "            # Encode first\n",
    "            memory = transformer.encode(src, src_mask)\n",
    "\n",
    "            # Train decoder\n",
    "            logits = model(memory, tgt_input, tgt_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "            # Calculate loss\n",
    "            tgt_out = text[1:,:]\n",
    "            loss = crit1(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            losses += loss.item()\n",
    "\n",
    "        return losses / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "\n",
    "crit1 = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(classification_model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    train_loss = train(text_styler, train_dataloader, crit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
